{
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "isInternetEnabled": true,
      "isGpuEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "DATASET_PATH = \"/kaggle/input/datasets/shreann/imdb-dataset\"\n",
        "print(os.listdir(DATASET_PATH))\n",
        "\n",
        "messages = pd.read_csv(f\"{DATASET_PATH}/IMDBDataset.csv\")\n",
        "messages.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "corpus = []\n",
        "for i in range(len(messages)):\n",
        "    rev = re.sub('[^a-zA-Z]', ' ', str(messages['review'][i]))\n",
        "    rev = rev.lower()\n",
        "    rev = rev.split()\n",
        "\n",
        "    clean_words = []\n",
        "    for word in rev:\n",
        "        if word not in stop_words:\n",
        "            clean_words.append(lemmatizer.lemmatize(word))\n",
        "\n",
        "    rev = ' '.join(clean_words)\n",
        "    corpus.append(rev)\n",
        "\n",
        "# Bag of Words\n",
        "cv = CountVectorizer(max_features=2000)\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "\n",
        "y = pd.get_dummies(messages['sentiment'])\n",
        "y = y.iloc[:, 1].values\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=0\n",
        ")\n",
        "\n",
        "# Naive Bayes Model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "confusion_m = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(confusion_m)\n",
        "print(accuracy)\n"
      ]
    }
  ]
}
